{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0z6xyOFvpORX",
        "outputId": "0a55b2d9-46b2-4376-8653-da9c49963b10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Cloning into 'Car-vs-bike'...\n",
            "remote: Enumerating objects: 3981, done.\u001b[K\n",
            "remote: Total 3981 (delta 0), reused 0 (delta 0), pack-reused 3981\u001b[K\n",
            "Receiving objects: 100% (3981/3981), 102.13 MiB | 36.14 MiB/s, done.\n"
          ]
        }
      ],
      "source": [
        "!git clone \"https://github.com/RA2112704010015/Car-vs-bike.git\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "ebWLkBTyz4Oe"
      },
      "outputs": [],
      "source": [
        "##Importing the libraries\n",
        "import tensorflow as tf\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fy6uSG-Oz9Tr",
        "outputId": "b5df9766-d3e1-4c19-8f9c-eac4d0e36c81"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3200 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
        "                                   shear_range = 0.2,\n",
        "                                   zoom_range = 0.2,\n",
        "                                   horizontal_flip = True)\n",
        "\n",
        "training_set = train_datagen.flow_from_directory('/content/Car-vs-bike/Dataset/Train',\n",
        "                                                 target_size = (64, 64),\n",
        "                                                 batch_size = 32,\n",
        "                                                 class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NBerz9X20AcL",
        "outputId": "16aa4189-faaa-47f2-fe5b-7c82ab4ed2ba"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 800 images belonging to 2 classes.\n"
          ]
        }
      ],
      "source": [
        "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
        "test_set = test_datagen.flow_from_directory('/content/Car-vs-bike/Dataset/Test',\n",
        "                                            target_size = (64, 64),\n",
        "                                            batch_size = 32,\n",
        "                                            class_mode = 'binary')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTDSH8iF0CHF"
      },
      "source": [
        "###Building CNN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "EO8_NGVz0Bj5"
      },
      "outputs": [],
      "source": [
        "cnn = tf.keras.models.Sequential()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "nvMZYy-d0LWQ"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu',\n",
        "                               input_shape=[64, 64, 3]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "__ZCGPnV0PH9"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "zIGh1H8-0QSM"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n",
        "cnn.add(tf.keras.layers.MaxPool2D(pool_size=2, strides=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "7xx4VrxS0Rrb"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Flatten())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "hFy9DlUw0Vw7"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=256, activation='relu'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "bEwbgdw00ZvX"
      },
      "outputs": [],
      "source": [
        "cnn.add(tf.keras.layers.Dense(units=1, activation='sigmoid'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "c7Llg0Gj0bYy"
      },
      "outputs": [],
      "source": [
        "cnn.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dcTRlhuw0daE",
        "outputId": "e4b7f499-ca95-4723-f8eb-951948098d3b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "100/100 [==============================] - ETA: 0s - loss: 0.5937 - accuracy: 0.6919"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\r100/100 [==============================] - 30s 291ms/step - loss: 0.5937 - accuracy: 0.6919 - val_loss: 0.2957 - val_accuracy: 0.8975\n",
            "Epoch 2/40\n",
            "100/100 [==============================] - 28s 284ms/step - loss: 0.3277 - accuracy: 0.8625 - val_loss: 0.4565 - val_accuracy: 0.8200\n",
            "Epoch 3/40\n",
            "100/100 [==============================] - 29s 285ms/step - loss: 0.2537 - accuracy: 0.8938 - val_loss: 0.2319 - val_accuracy: 0.9150\n",
            "Epoch 4/40\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.2536 - accuracy: 0.8950 - val_loss: 0.2540 - val_accuracy: 0.9013\n",
            "Epoch 5/40\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.2217 - accuracy: 0.9087 - val_loss: 0.3189 - val_accuracy: 0.8850\n",
            "Epoch 6/40\n",
            "100/100 [==============================] - 28s 276ms/step - loss: 0.2171 - accuracy: 0.9153 - val_loss: 0.2675 - val_accuracy: 0.8975\n",
            "Epoch 7/40\n",
            "100/100 [==============================] - 30s 303ms/step - loss: 0.2117 - accuracy: 0.9147 - val_loss: 0.2470 - val_accuracy: 0.9087\n",
            "Epoch 8/40\n",
            "100/100 [==============================] - 29s 281ms/step - loss: 0.2007 - accuracy: 0.9187 - val_loss: 0.4050 - val_accuracy: 0.8537\n",
            "Epoch 9/40\n",
            "100/100 [==============================] - 28s 278ms/step - loss: 0.1823 - accuracy: 0.9287 - val_loss: 0.2207 - val_accuracy: 0.9250\n",
            "Epoch 10/40\n",
            "100/100 [==============================] - 27s 275ms/step - loss: 0.1616 - accuracy: 0.9337 - val_loss: 0.2742 - val_accuracy: 0.9125\n",
            "Epoch 11/40\n",
            "100/100 [==============================] - 27s 272ms/step - loss: 0.1592 - accuracy: 0.9375 - val_loss: 0.2770 - val_accuracy: 0.9075\n",
            "Epoch 12/40\n",
            "100/100 [==============================] - 27s 271ms/step - loss: 0.1612 - accuracy: 0.9375 - val_loss: 0.6475 - val_accuracy: 0.8150\n",
            "Epoch 13/40\n",
            "100/100 [==============================] - 27s 274ms/step - loss: 0.1569 - accuracy: 0.9378 - val_loss: 0.2395 - val_accuracy: 0.9150\n",
            "Epoch 14/40\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.1491 - accuracy: 0.9406 - val_loss: 0.3222 - val_accuracy: 0.9038\n",
            "Epoch 15/40\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.1442 - accuracy: 0.9444 - val_loss: 0.2006 - val_accuracy: 0.9400\n",
            "Epoch 16/40\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.1213 - accuracy: 0.9506 - val_loss: 0.2161 - val_accuracy: 0.9287\n",
            "Epoch 17/40\n",
            "100/100 [==============================] - 27s 268ms/step - loss: 0.1194 - accuracy: 0.9519 - val_loss: 0.2413 - val_accuracy: 0.9187\n",
            "Epoch 18/40\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.1347 - accuracy: 0.9481 - val_loss: 0.1950 - val_accuracy: 0.9287\n",
            "Epoch 19/40\n",
            "100/100 [==============================] - 27s 267ms/step - loss: 0.1151 - accuracy: 0.9597 - val_loss: 0.2343 - val_accuracy: 0.9250\n",
            "Epoch 20/40\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.1041 - accuracy: 0.9600 - val_loss: 0.3256 - val_accuracy: 0.9087\n",
            "Epoch 21/40\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.1059 - accuracy: 0.9603 - val_loss: 0.4435 - val_accuracy: 0.8750\n",
            "Epoch 22/40\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0993 - accuracy: 0.9647 - val_loss: 0.2625 - val_accuracy: 0.9175\n",
            "Epoch 23/40\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0853 - accuracy: 0.9647 - val_loss: 0.2259 - val_accuracy: 0.9312\n",
            "Epoch 24/40\n",
            "100/100 [==============================] - 26s 263ms/step - loss: 0.0846 - accuracy: 0.9709 - val_loss: 0.2798 - val_accuracy: 0.9187\n",
            "Epoch 25/40\n",
            "100/100 [==============================] - 26s 259ms/step - loss: 0.0952 - accuracy: 0.9616 - val_loss: 0.3069 - val_accuracy: 0.9125\n",
            "Epoch 26/40\n",
            "100/100 [==============================] - 26s 261ms/step - loss: 0.0957 - accuracy: 0.9609 - val_loss: 0.2105 - val_accuracy: 0.9388\n",
            "Epoch 27/40\n",
            "100/100 [==============================] - 31s 310ms/step - loss: 0.1035 - accuracy: 0.9613 - val_loss: 0.2948 - val_accuracy: 0.9287\n",
            "Epoch 28/40\n",
            "100/100 [==============================] - 30s 299ms/step - loss: 0.0673 - accuracy: 0.9737 - val_loss: 0.2517 - val_accuracy: 0.9262\n",
            "Epoch 29/40\n",
            "100/100 [==============================] - 28s 279ms/step - loss: 0.0810 - accuracy: 0.9675 - val_loss: 0.2429 - val_accuracy: 0.9300\n",
            "Epoch 30/40\n",
            "100/100 [==============================] - 27s 273ms/step - loss: 0.0854 - accuracy: 0.9666 - val_loss: 0.4559 - val_accuracy: 0.8888\n",
            "Epoch 31/40\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0648 - accuracy: 0.9750 - val_loss: 0.3056 - val_accuracy: 0.9125\n",
            "Epoch 32/40\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0653 - accuracy: 0.9784 - val_loss: 0.3151 - val_accuracy: 0.9175\n",
            "Epoch 33/40\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0686 - accuracy: 0.9753 - val_loss: 0.2750 - val_accuracy: 0.9262\n",
            "Epoch 34/40\n",
            "100/100 [==============================] - 26s 264ms/step - loss: 0.0704 - accuracy: 0.9741 - val_loss: 0.2750 - val_accuracy: 0.9262\n",
            "Epoch 35/40\n",
            "100/100 [==============================] - 26s 262ms/step - loss: 0.0558 - accuracy: 0.9797 - val_loss: 0.3560 - val_accuracy: 0.9100\n",
            "Epoch 36/40\n",
            "100/100 [==============================] - 26s 257ms/step - loss: 0.0423 - accuracy: 0.9862 - val_loss: 0.2838 - val_accuracy: 0.9262\n",
            "Epoch 37/40\n",
            "100/100 [==============================] - 27s 266ms/step - loss: 0.0469 - accuracy: 0.9862 - val_loss: 0.2787 - val_accuracy: 0.9325\n",
            "Epoch 38/40\n",
            "100/100 [==============================] - 27s 265ms/step - loss: 0.0520 - accuracy: 0.9819 - val_loss: 0.2693 - val_accuracy: 0.9300\n",
            "Epoch 39/40\n",
            "100/100 [==============================] - 26s 258ms/step - loss: 0.0407 - accuracy: 0.9859 - val_loss: 0.3417 - val_accuracy: 0.9250\n",
            "Epoch 40/40\n",
            "100/100 [==============================] - 27s 270ms/step - loss: 0.0364 - accuracy: 0.9869 - val_loss: 0.4106 - val_accuracy: 0.9150\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7d17c8d36b60>"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "cnn.fit(x = training_set, validation_data = test_set, epochs = 40)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rVFdTWlv0fAV",
        "outputId": "2564dab5-47fd-4049-eb3c-1fda778c3a48"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d (Conv2D)             (None, 62, 62, 32)        896       \n",
            "                                                                 \n",
            " max_pooling2d (MaxPooling2  (None, 31, 31, 32)        0         \n",
            " D)                                                              \n",
            "                                                                 \n",
            " conv2d_1 (Conv2D)           (None, 29, 29, 32)        9248      \n",
            "                                                                 \n",
            " max_pooling2d_1 (MaxPoolin  (None, 14, 14, 32)        0         \n",
            " g2D)                                                            \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 6272)              0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 256)               1605888   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 257       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1616289 (6.17 MB)\n",
            "Trainable params: 1616289 (6.17 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "cnn.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eb-xNYoU0goO",
        "outputId": "7d2cf349-4133-49fa-82aa-e6120c5ed4e5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 23ms/step\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = tf.keras.utils.load_img('/content/bike.jpeg',\n",
        "                            target_size = (64, 64))\n",
        "#test_image = tf.keras.utils.load_img(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'Bike'\n",
        "else:\n",
        "  prediction = 'car'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GM96xRrU0hkc",
        "outputId": "36d2c636-e881-43d0-e416-6fcd340abee9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bike\n"
          ]
        }
      ],
      "source": [
        "print(prediction)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bOw3_gtPYtGd",
        "outputId": "40d32500-3a59-4783-ba21-0f9c40cd80af"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 42ms/step\n",
            "car\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "\n",
        "test_image = tf.keras.utils.load_img('/content/car.jpeg',\n",
        "                            target_size = (64, 64))\n",
        "#test_image = tf.keras.utils.load_img(test_image)\n",
        "test_image = np.expand_dims(test_image, axis = 0)\n",
        "result = cnn.predict(test_image)\n",
        "training_set.class_indices\n",
        "if result[0][0] == 0:\n",
        "  prediction = 'Bike'\n",
        "else:\n",
        "  prediction = 'car'\n",
        "\n",
        "print(prediction)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
